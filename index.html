<!DOCTYPE html>
<html lang="en">
	<head>
		<title>jian vora</title>
		<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
		<link rel="stylesheet" href="css/main.css">
		<style>
			* {
			   box-sizing: border-box;
			}
			.imageColumn {
			   float: left;
			   width: 25%;
			   padding: 10px;
			}
			h1{
			   text-align: center;
			}
			</style>
			
		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-103320786-1', 'auto');
			ga('send', 'pageview');
		</script>
	</head>
	<body>
		<div class="container">
			<div class="page-header">
				<h2>jian vora 
				<p><small><a href="mailto:jianv@cs.stanford.edu">email, </a><a href="https://github.com/jianvora">github, </a><a href="https://www.linkedin.com/in/jianvora/">linkedin</a></small></h2></p>
				<div class="alignRow">
					<div class="imageColumn">
					<img src="images/me.jpg" alt="Snow" style="width:100%">
					</div>
					<div class="imageColumn">
					<img src="images/me2.jpg" alt="Forest" style="width:100%">
					</div>
				</div>
					
			
				<!-- <p class="profpic"><img src="images/me2.jpg" width="255px"
				/></p>
				<p class="profpic"><img src="images/me.jpg" width="255px"
				 /></p> -->
				<!-- <p><a href="https://github.com/jianvora">github</a>
				|Â <a href="https://www.linkedin.com/in/jianvora/">linkedin</a> -->

				</p>
			</div>

			<p>i am a second year ms student at stanford in the computer science department. before that, i was a naive undergrad at iit bombay. i (pretend to) work on neural nonsense.
				 you can find me in one of my two natural eigenstates (images on the left).
			</p>

			<p>i am interested in the mathematical foundations of machine learning, which translates to learning and infering over high-dimensions efficiently. i am interested in reinforcement learning. in the past, i have worked on sparse recovery, tractable inference, and sequential decision-making problems. i have done some internships where i did funky deep learning.</p>

			<p> i am a sota neural net capable of (a) few-shot meta adaptation, (b) robust to adversarial attacks, and (c) in-context learning abilities. i can be trained very easily by showing me few slices of pizza instead to expensive gpus. i like working on fun real-world applications of machine learning. in my free time, i like to cook. </p>

<!-- 			<h3>Recent</h3>
			<p><strong>Reviewer</strong>: ICLR 2020, AAAI 2020, NeurIPS 2019, ICML 2019, ICLR 2019, R2L Workshop (NeurIPS 2018).<p> -->

			<!-- <dl>
				<dt>Neural Network Compression for Noisy Storage Devices.</dt>
				<dd>Berivan Isik, <b>Kristy Choi</b>, Xin Zheng, Tsachy Weissman, Stefano Ermon, H.-S. Philip Wong, Armin Alaghi</dd>
				<dd><i>arXiv preprint, 2021.</i></dd>
				<dd><a href="https://arxiv.org/abs/2102.07725">[arXiv]</a>[code soon]</dd>
			</dl> -->
<!-- 			<dl>
				<dt>Tensor Decomposition for Single-cell RNA-seq Data.</dt>
				<dd><b>Kristy Choi*</b>, Ambrose J. Carr*, Sandhya Prabhakaran, Dana Pe'er</dd>
				<dd><i>Practical Bayesian Nonparametrics Workshop, NeurIPS 2016. </i></dd>
				<dd><a href="https://drive.google.com/file/d/0B3WHb3BabixAb2RfMmc4eUJjUE0/view">[pdf]</a></dd>
			</dl> -->

			<h3>publications</h3>

			<dl>
				<dt><a href="https://proceedings.mlr.press/v151/anand-jain22a/anand-jain22a.pdf">pac mode estimation using ppr martingale confidence sequences</a></dt>
				<dd> shubham jain, rohan shah, sanit gupta*, denil mehta*, inderjeet nair*, <b>jian vora*</b>, sushil khyalia, sourav das, vinay riberio, shivaram kalyankrishnan</dd>
				<dd> asymptotically optimal mode estimation of a discrete distribution by construcing confidence sequences (1v1, 1vr); applications to election polls and contract verification in blockchains </dd>
			</dl>

			<dl>
				<dt><a href="https://ieeexplore.ieee.org/abstract/document/9513818">recovery of joint probability distribution from
					one-way marginals: low rank tensors and random projections</a></dt>
				<dd> <b>jian vora</b>, karthik gurumoorthy, ajit rajwade</dd>
				<dd>model a joint pmf as a low-rank tensor, recover the mode factors from 1D marginals estimated from random projections of data </dd>
			</dl>

			<dl>
				<dt><a href="https://ieeexplore.ieee.org/abstract/document/9413470">compressive signal recovery under sensing matrix errors combined
					with unknown measurement gains</a></dt>
				<dd> <b>jian vora</b>, ajit rajwade</dd>
				<dd>compressive recovery when the sensing matrix is misspecified and there are unknown sensor gains </dd>
			</dl>

			<h3>preprints</h3>
			<dl>
				<dt><a href="https://arxiv.org/pdf/2210.17140.pdf">scoring black-box models for adversarial robustness</a></dt>
				<dd><b>jian vora</b>, pranay reddy samala</dd>
				<dd>adversarially robust models have sharper explanations and sparser lime weights, use this as a good subsitute for robust accuracy where trying to find attacks to the model can be hard</dd>
			</dl>

			<dl>
				<dt><a href="data/PPPC.pdf">plug&play multimodal generative model
					allowing tractable inference</a></dt>
				<dd><b>jian vora</b>, isabel valera, guy van den broeck, antonio vergari</dd>
				<dd>learn a joint distribution over multiple modalities while allowing for efficient marginalization, conditioning, likelihood evaluation using probabilisitc circuits on the fused latent space </dd>
			</dl>

			<dl>
				<dt><a href="data/AWS-speech-text.pdf">joint
					speech-text pre-training with application to text adaptation for asr</a></dt>
				<dd><b>jian vora</b>, cekic metehan, dhanush bekal, karel mundnich, srikanth ronanki, katrin kirchoff</dd>
				<dd>a hubert-based shared encoder for speech and text modalities for better coherence in embeddings using a small amount of paired multimodal data, application to text adaptation for asr </dd>
			</dl>
			


			<h3>other selected research + course projects</h3>
			<dl>
				<dt><a href="data/SRE_Report_JianVora.pdf">efficient learning of log-concave mixtures</a></dt>
				<dd><b>jian vora</b>, vivek borkar</dd>
				<dd>random projections of data drawn from a mixture of log-concave densities are provably distributed as a gaussian mixture in the subspace</dd>
			</dl>

			<dl>
				<dt><a href="data/CS333_Final_Report.pdf">tractable cooperative multi-agent reinforcement learning</a></dt>
				<dd> learn a joint policy over actions of all agents allowing for efficient inference by modeling q-function to be a factor graph
					</dd>
			</dl>

			<dl>
				<dt><a href="data/CS_236_Final_Report.pdf">improving inference in latent variable models</a></dt>
				<dd> improved inference in VAEs by reducing two gaps -- approximation gap by using hierarchical VAEs and amortization gap by performing unamortized inference
					</dd>
			</dl>


			<dl>
				<dt><a href="https://www.researchgate.net/publication/337566411_NII_Hitachi_UIT_at_TRECVID_2019">spatio-temporal action detection and classification</a></dt>
				<dd>participated in the trecvid'19 challenge which involved performing action detection and classification in videos. proposed a stage-wise architecture of object detection followed by tracking and activity classification
					</dd>
			</dl>

			<dl>
				<dt><a href="data/ASR_Report.pdf">continual learning for keyword spotting and speaker identification</a></dt>
				<dd>proposed a joint model to perform simultaneous kws and sid based on an interspeech 2021 challenge</dd>
			</dl>

			<dl>
				<dt><a href="data/EE782_StyleGAN.pdf">conditional style-gan for audio generative modeling</a></dt>
				<dd>Modified stylegan to allow for conditioning and trained on audio spectrograms</dd>
			</dl>

			<h3>teaching</h3>
			<p><strong>fall 2022:</strong> course assistant
			for <a href="https://cs224v.stanford.edu/">cs224v: conversational virtual assistants with deep learning</a> at stanford<p>
			<p><strong>winter 2022:</strong> course assistant
			for <a href="https://cs236g.stanford.edu/">cs236g: generative adversarial networks</a> at stanford<p>
			<p><strong>spring 2021:</strong> teaching assistant
			for ma111: vector calculus at iitb<p>

			<h3>service</h3>
			<p><strong>reviewer</strong>: tmlr, ieee tsp, aaai<p>
			<p><strong>leadership</strong>: manager, electronics and robotics club
			<br><br>
		</div>
	</body>
</html>
